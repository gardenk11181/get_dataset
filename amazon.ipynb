{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import pickle5 as pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "dir_path = 'G:\\내 드라이브\\data\\\\amazon\\\\'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "domains = ['books', 'dvd', 'electronics', 'kitchen']\n",
    "kinds = ['negative', 'positive', 'unlabeled']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def preprocess_words(words: list) -> str:\n",
    "    document = ''\n",
    "    for i in range(len(words)):\n",
    "        tmp = words[i].split(':')\n",
    "        for j in range(int(tmp[1])):\n",
    "            document += tmp[0] + ' '\n",
    "    return document"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def file_to_corpus(file: io.TextIOWrapper) -> (list, list):\n",
    "    corpus = []\n",
    "    labels = []\n",
    "    for review in file:\n",
    "        contents = review.split()\n",
    "        words = contents[:-1]\n",
    "        document = preprocess_words(words)\n",
    "        label = contents[-1].split(':')[1]\n",
    "        y = 0 if label == 'negative' else 1\n",
    "        corpus.append(document)\n",
    "        labels.append(y)\n",
    "    return corpus, labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "for domain in domains:\n",
    "    save_path = dir_path + '%s/%s.pkl' % (domain, domain)\n",
    "    corpus_train = []\n",
    "    corpus_test = []\n",
    "    labels_train = []\n",
    "    labels_test = []\n",
    "    # training set (labeled)\n",
    "    for kind in kinds[:-1]:\n",
    "        file_path = dir_path + '%s/%s.review' % (domain, kind)\n",
    "        with open(file_path, 'r', encoding='UTF8') as r:\n",
    "            corpus, labels = file_to_corpus(r)\n",
    "            corpus_train.extend(corpus)\n",
    "            labels_train.extend(labels)\n",
    "    # test set (unlabeled)\n",
    "    file_path = dir_path + '%s/%s.review' % (domain, kinds[-1])\n",
    "    with open(file_path, 'r', encoding='UTF8') as r:\n",
    "        corpus, labels = file_to_corpus(r)\n",
    "        corpus_test.extend(corpus)\n",
    "        labels_test.extend(labels)\n",
    "    with open(save_path, 'wb') as w:\n",
    "        pickle.dump([corpus_train, labels_train, corpus_test, labels_test], w)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "corpus_trains = []\n",
    "labels_trains = []\n",
    "corpus_tests = []\n",
    "labels_tests = []\n",
    "for domain in domains:\n",
    "    save_path = dir_path + '%s/%s.pkl' % (domain, domain)\n",
    "    with open(save_path, 'rb') as r:\n",
    "        corpus_train, labels_train, corpus_test, labels_test = pickle.load(r)\n",
    "    corpus_trains.append(corpus_train)\n",
    "    corpus_tests.append(corpus_test)\n",
    "    labels_trains.append(labels_train)\n",
    "    labels_tests.append(labels_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:\\내 드라이브\\data\\amazon\\/books_to_dvd.pkl\n",
      "G:\\내 드라이브\\data\\amazon\\/books_to_electronics.pkl\n",
      "G:\\내 드라이브\\data\\amazon\\/books_to_kitchen.pkl\n",
      "G:\\내 드라이브\\data\\amazon\\/dvd_to_books.pkl\n",
      "G:\\내 드라이브\\data\\amazon\\/dvd_to_electronics.pkl\n",
      "G:\\내 드라이브\\data\\amazon\\/dvd_to_kitchen.pkl\n",
      "G:\\내 드라이브\\data\\amazon\\/electronics_to_books.pkl\n",
      "G:\\내 드라이브\\data\\amazon\\/electronics_to_dvd.pkl\n",
      "G:\\내 드라이브\\data\\amazon\\/electronics_to_kitchen.pkl\n",
      "G:\\내 드라이브\\data\\amazon\\/kitchen_to_books.pkl\n",
      "G:\\내 드라이브\\data\\amazon\\/kitchen_to_dvd.pkl\n",
      "G:\\내 드라이브\\data\\amazon\\/kitchen_to_electronics.pkl\n"
     ]
    }
   ],
   "source": [
    "for i, source in enumerate(domains):\n",
    "    for j, target in enumerate(domains):\n",
    "        if i == j: continue\n",
    "        corpus = []\n",
    "        corpus.extend(corpus_trains[i])\n",
    "        corpus.extend(corpus_trains[j])\n",
    "        tf_idf = TfidfVectorizer(max_features=5000)\n",
    "        tf_idf.fit_transform(corpus)\n",
    "        source_train = tf_idf.transform(corpus_trains[i])\n",
    "        source_train_y = pd.Series(labels_trains[i])\n",
    "        target_train = tf_idf.transform(corpus_trains[j])\n",
    "        target_test = tf_idf.transform(corpus_tests[j])\n",
    "        target_test_y = pd.Series(labels_tests[j])\n",
    "        save_path = dir_path + '/%s_to_%s.pkl' % (source, target)\n",
    "        print(save_path)\n",
    "        with open(save_path, 'wb') as w:\n",
    "            pickle.dump([(source_train, source_train_y), target_train, (target_test, target_test_y)], w)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3586, 5000)\n"
     ]
    }
   ],
   "source": [
    "tmp_path = dir_path + '/books_to_dvd.pkl'\n",
    "with open(tmp_path, 'rb') as r:\n",
    "    data = pickle.load(r)\n",
    "print(data[2][0].shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}